########################BERTurk (uncased, 128k)###############

2024-01-18 20:10:10 : WARNING  Load doc_token embedding from r_bert_embed_tr.pkl
2024-01-18 20:10:11 : WARNING  Total dict size of doc_token is 39439
2024-01-18 20:10:11 : WARNING  Size of pretrained doc_token embedding is 30073
2024-01-18 20:10:11 : WARNING  Size of randomly initialize doc_token embedding is 9366
2024-01-18 20:10:33 : WARNING  dataset name: shuffled_dataset_bert_128k
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 2, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 4
loss type: SigmoidFocalCrossEntropy
optimizer: Adam
learning rate: 0.002

2024-01-18 20:10:33 : WARNING  Train performance at epoch 1 is precision: 0.900561, recall: 0.900561, fscore: 0.900561, macro-fscore: 0.900932, right: 2409, predict: 2675, standard: 2675.
Loss is: 0.033866.
2024-01-18 20:10:40 : WARNING  Validate performance at epoch 1 is precision: 0.883408, recall: 0.883408, fscore: 0.883408, macro-fscore: 0.883702, right: 591, predict: 669, standard: 669.
Loss is: 0.035690.
2024-01-18 20:10:50 : WARNING  test performance at epoch 1 is precision: 0.878924, recall: 0.878924, fscore: 0.878924, macro-fscore: 0.878643, right: 980, predict: 1115, standard: 1115.
Loss is: 0.037344.
2024-01-18 20:11:08 : WARNING  Train performance at epoch 2 is precision: 0.899065, recall: 0.899065, fscore: 0.899065, macro-fscore: 0.905280, right: 2405, predict: 2675, standard: 2675.
Loss is: 0.029835.
2024-01-18 20:11:15 : WARNING  Validate performance at epoch 2 is precision: 0.890882, recall: 0.890882, fscore: 0.890882, macro-fscore: 0.896980, right: 596, predict: 669, standard: 669.
Loss is: 0.033309.
2024-01-18 20:11:23 : WARNING  test performance at epoch 2 is precision: 0.881614, recall: 0.881614, fscore: 0.881614, macro-fscore: 0.887143, right: 983, predict: 1115, standard: 1115.
Loss is: 0.035565.
2024-01-18 20:11:39 : WARNING  Train performance at epoch 3 is precision: 0.962243, recall: 0.962243, fscore: 0.962243, macro-fscore: 0.962818, right: 2574, predict: 2675, standard: 2675.
Loss is: 0.020425.
2024-01-18 20:11:46 : WARNING  Validate performance at epoch 3 is precision: 0.935725, recall: 0.935725, fscore: 0.935725, macro-fscore: 0.936139, right: 626, predict: 669, standard: 669.
Loss is: 0.025677.
2024-01-18 20:11:54 : WARNING  test performance at epoch 3 is precision: 0.928251, recall: 0.928251, fscore: 0.928251, macro-fscore: 0.928918, right: 1035, predict: 1115, standard: 1115.
Loss is: 0.029965.
2024-01-18 20:12:10 : WARNING  Train performance at epoch 4 is precision: 0.982056, recall: 0.982056, fscore: 0.982056, macro-fscore: 0.982113, right: 2627, predict: 2675, standard: 2675.
Loss is: 0.011314.
2024-01-18 20:12:17 : WARNING  Validate performance at epoch 4 is precision: 0.955157, recall: 0.955157, fscore: 0.955157, macro-fscore: 0.955234, right: 639, predict: 669, standard: 669.
Loss is: 0.017218.
2024-01-18 20:12:25 : WARNING  test performance at epoch 4 is precision: 0.944395, recall: 0.944395, fscore: 0.944395, macro-fscore: 0.944291, right: 1053, predict: 1115, standard: 1115.
Loss is: 0.020346.
2024-01-18 20:12:33 : WARNING  Best test performance at epoch 4 is precision: 0.944395, recall: 0.944395, fscore: 0.944395, macro-fscore: 0.944291, right: 1053, predict: 1115, standard: 1115.
Loss is: 0.020346.

################ bert embeddings, bert tokenized##############
################# english best###############################
2024-01-19 23:25:15 : WARNING  Load doc_token embedding from r_embeddings_dict_bert_tr_mc4.pkl
2024-01-19 23:25:16 : WARNING  Total dict size of doc_token is 25321
2024-01-19 23:25:16 : WARNING  Size of pretrained doc_token embedding is 20887
2024-01-19 23:25:16 : WARNING  Size of randomly initialize doc_token embedding is 4434
2024-01-20 19:32:28 : WARNING  Load doc_token embedding from r_embeddings_dict_bert_tr_mc4.pkl
2024-01-20 19:32:29 : WARNING  Total dict size of doc_token is 26693
2024-01-20 19:32:29 : WARNING  Size of pretrained doc_token embedding is 2024
2024-01-20 19:32:29 : WARNING  Size of randomly initialize doc_token embedding is 24669
2024-01-20 19:34:04 : WARNING  Load doc_token embedding from r_bert_embeddings_en_unique_tokens.pkl
2024-01-20 19:34:05 : WARNING  Total dict size of doc_token is 26693
2024-01-20 19:34:05 : WARNING  Size of pretrained doc_token embedding is 26687
2024-01-20 19:34:05 : WARNING  Size of randomly initialize doc_token embedding is 6
2024-01-20 19:35:54 : WARNING  dataset name: shuffled_dataset_bert
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 2, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 4
loss type: SigmoidFocalCrossEntropy
optimizer: Adam
learning rate: 0.002

2024-01-20 19:35:54 : WARNING  Train performance at epoch 1 is precision: 0.964860, recall: 0.964860, fscore: 0.964860, macro-fscore: 0.963205, right: 74602, predict: 77319, standard: 77319.
Loss is: 0.016479.
2024-01-20 19:36:59 : WARNING  Validate performance at epoch 1 is precision: 0.963168, recall: 0.963168, fscore: 0.963168, macro-fscore: 0.961436, right: 18619, predict: 19331, standard: 19331.
Loss is: 0.016677.
2024-01-20 19:38:33 : WARNING  test performance at epoch 1 is precision: 0.959151, recall: 0.959151, fscore: 0.959151, macro-fscore: 0.957266, right: 30900, predict: 32216, standard: 32216.
Loss is: 0.017188.
2024-01-20 19:40:24 : WARNING  Train performance at epoch 2 is precision: 0.978686, recall: 0.978686, fscore: 0.978686, macro-fscore: 0.977711, right: 75671, predict: 77319, standard: 77319.
Loss is: 0.010539.
2024-01-20 19:41:25 : WARNING  Validate performance at epoch 2 is precision: 0.969893, recall: 0.969893, fscore: 0.969893, macro-fscore: 0.968508, right: 18749, predict: 19331, standard: 19331.
Loss is: 0.012024.
2024-01-20 19:42:57 : WARNING  test performance at epoch 2 is precision: 0.969736, recall: 0.969736, fscore: 0.969736, macro-fscore: 0.968391, right: 31241, predict: 32216, standard: 32216.
Loss is: 0.012187.
2024-01-20 19:44:57 : WARNING  Train performance at epoch 3 is precision: 0.981040, recall: 0.981040, fscore: 0.981040, macro-fscore: 0.980161, right: 75853, predict: 77319, standard: 77319.
Loss is: 0.014695.
2024-01-20 19:46:03 : WARNING  Validate performance at epoch 3 is precision: 0.971859, recall: 0.971859, fscore: 0.971859, macro-fscore: 0.970544, right: 18787, predict: 19331, standard: 19331.
Loss is: 0.016171.
2024-01-20 19:47:39 : WARNING  test performance at epoch 3 is precision: 0.969425, recall: 0.969425, fscore: 0.969425, macro-fscore: 0.968030, right: 31231, predict: 32216, standard: 32216.
Loss is: 0.016333.
2024-01-20 19:49:36 : WARNING  Train performance at epoch 4 is precision: 0.985217, recall: 0.985217, fscore: 0.985217, macro-fscore: 0.984548, right: 76176, predict: 77319, standard: 77319.
Loss is: 0.007953.
2024-01-20 19:50:39 : WARNING  Validate performance at epoch 4 is precision: 0.971962, recall: 0.971962, fscore: 0.971962, macro-fscore: 0.970674, right: 18789, predict: 19331, standard: 19331.
Loss is: 0.010843.
2024-01-20 19:52:12 : WARNING  test performance at epoch 4 is precision: 0.970605, recall: 0.970605, fscore: 0.970605, macro-fscore: 0.969290, right: 31269, predict: 32216, standard: 32216.
Loss is: 0.010826.
2024-01-20 19:53:47 : WARNING  Best test performance at epoch 4 is precision: 0.970605, recall: 0.970605, fscore: 0.970605, macro-fscore: 0.969290, right: 31269, predict: 32216, standard: 32216.
Loss is: 0.010826.


####Turkish dataset, berconv embeddings, tokenization (mc4)##
2024-01-20 23:09:37 : WARNING  Load doc_token embedding from r_turkish_bertconv_mc4.pkl
2024-01-20 23:09:37 : WARNING  Total dict size of doc_token is 25321
2024-01-20 23:09:37 : WARNING  Size of pretrained doc_token embedding is 25318
2024-01-20 23:09:37 : WARNING  Size of randomly initialize doc_token embedding is 3
2024-01-20 23:10:11 : WARNING  Load doc_token embedding from r_turkish_bertconv_mc4.pkl
2024-01-20 23:10:12 : WARNING  Total dict size of doc_token is 25321
2024-01-20 23:10:12 : WARNING  Size of pretrained doc_token embedding is 25318
2024-01-20 23:10:12 : WARNING  Size of randomly initialize doc_token embedding is 3
2024-01-20 23:10:34 : WARNING  dataset name: shuffled_dataset_bert
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 2, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 4
loss type: SigmoidFocalCrossEntropy
optimizer: Adam
learning rate: 0.002

2024-01-20 23:10:34 : WARNING  Train performance at epoch 1 is precision: 0.863178, recall: 0.863178, fscore: 0.863178, macro-fscore: 0.867055, right: 2309, predict: 2675, standard: 2675.
Loss is: 0.050800.
2024-01-20 23:10:43 : WARNING  Validate performance at epoch 1 is precision: 0.856502, recall: 0.856502, fscore: 0.856502, macro-fscore: 0.857665, right: 573, predict: 669, standard: 669.
Loss is: 0.051112.
2024-01-20 23:10:54 : WARNING  test performance at epoch 1 is precision: 0.824215, recall: 0.824215, fscore: 0.824215, macro-fscore: 0.823946, right: 919, predict: 1115, standard: 1115.
Loss is: 0.050261.
2024-01-20 23:11:14 : WARNING  Train performance at epoch 2 is precision: 0.902430, recall: 0.902430, fscore: 0.902430, macro-fscore: 0.902449, right: 2414, predict: 2675, standard: 2675.
Loss is: 0.041764.
2024-01-20 23:11:23 : WARNING  Validate performance at epoch 2 is precision: 0.898356, recall: 0.898356, fscore: 0.898356, macro-fscore: 0.898832, right: 601, predict: 669, standard: 669.
Loss is: 0.044091.
2024-01-20 23:11:34 : WARNING  test performance at epoch 2 is precision: 0.861883, recall: 0.861883, fscore: 0.861883, macro-fscore: 0.860986, right: 961, predict: 1115, standard: 1115.
Loss is: 0.045715.
2024-01-20 23:11:54 : WARNING  Train performance at epoch 3 is precision: 0.948785, recall: 0.948785, fscore: 0.948785, macro-fscore: 0.949783, right: 2538, predict: 2675, standard: 2675.
Loss is: 0.028278.
2024-01-20 23:12:03 : WARNING  Validate performance at epoch 3 is precision: 0.911809, recall: 0.911809, fscore: 0.911809, macro-fscore: 0.914594, right: 610, predict: 669, standard: 669.
Loss is: 0.033711.
2024-01-20 23:12:13 : WARNING  test performance at epoch 3 is precision: 0.898655, recall: 0.898655, fscore: 0.898655, macro-fscore: 0.902021, right: 1002, predict: 1115, standard: 1115.
Loss is: 0.034330.
2024-01-20 23:12:33 : WARNING  Train performance at epoch 4 is precision: 0.972710, recall: 0.972710, fscore: 0.972710, macro-fscore: 0.973054, right: 2602, predict: 2675, standard: 2675.
Loss is: 0.019646.
2024-01-20 23:12:42 : WARNING  Validate performance at epoch 4 is precision: 0.953662, recall: 0.953662, fscore: 0.953662, macro-fscore: 0.953756, right: 638, predict: 669, standard: 669.
Loss is: 0.024470.
2024-01-20 23:12:52 : WARNING  test performance at epoch 4 is precision: 0.936323, recall: 0.936323, fscore: 0.936323, macro-fscore: 0.936457, right: 1044, predict: 1115, standard: 1115.
Loss is: 0.026275.
2024-01-20 23:13:03 : WARNING  Best test performance at epoch 4 is precision: 0.936323, recall: 0.936323, fscore: 0.936323, macro-fscore: 0.936457, right: 1044, predict: 1115, standard: 1115.
Loss is: 0.026275.
