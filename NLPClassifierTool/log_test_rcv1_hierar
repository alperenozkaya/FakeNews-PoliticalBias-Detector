########################BERTurk (uncased, 128k)###############

2024-01-18 20:10:10 : WARNING  Load doc_token embedding from r_bert_embed_tr.pkl
2024-01-18 20:10:11 : WARNING  Total dict size of doc_token is 39439
2024-01-18 20:10:11 : WARNING  Size of pretrained doc_token embedding is 30073
2024-01-18 20:10:11 : WARNING  Size of randomly initialize doc_token embedding is 9366
2024-01-18 20:10:33 : WARNING  dataset name: shuffled_dataset_bert_128k
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 2, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 4
loss type: SigmoidFocalCrossEntropy
optimizer: Adam
learning rate: 0.002

2024-01-18 20:10:33 : WARNING  Train performance at epoch 1 is precision: 0.900561, recall: 0.900561, fscore: 0.900561, macro-fscore: 0.900932, right: 2409, predict: 2675, standard: 2675.
Loss is: 0.033866.
2024-01-18 20:10:40 : WARNING  Validate performance at epoch 1 is precision: 0.883408, recall: 0.883408, fscore: 0.883408, macro-fscore: 0.883702, right: 591, predict: 669, standard: 669.
Loss is: 0.035690.
2024-01-18 20:10:50 : WARNING  test performance at epoch 1 is precision: 0.878924, recall: 0.878924, fscore: 0.878924, macro-fscore: 0.878643, right: 980, predict: 1115, standard: 1115.
Loss is: 0.037344.
2024-01-18 20:11:08 : WARNING  Train performance at epoch 2 is precision: 0.899065, recall: 0.899065, fscore: 0.899065, macro-fscore: 0.905280, right: 2405, predict: 2675, standard: 2675.
Loss is: 0.029835.
2024-01-18 20:11:15 : WARNING  Validate performance at epoch 2 is precision: 0.890882, recall: 0.890882, fscore: 0.890882, macro-fscore: 0.896980, right: 596, predict: 669, standard: 669.
Loss is: 0.033309.
2024-01-18 20:11:23 : WARNING  test performance at epoch 2 is precision: 0.881614, recall: 0.881614, fscore: 0.881614, macro-fscore: 0.887143, right: 983, predict: 1115, standard: 1115.
Loss is: 0.035565.
2024-01-18 20:11:39 : WARNING  Train performance at epoch 3 is precision: 0.962243, recall: 0.962243, fscore: 0.962243, macro-fscore: 0.962818, right: 2574, predict: 2675, standard: 2675.
Loss is: 0.020425.
2024-01-18 20:11:46 : WARNING  Validate performance at epoch 3 is precision: 0.935725, recall: 0.935725, fscore: 0.935725, macro-fscore: 0.936139, right: 626, predict: 669, standard: 669.
Loss is: 0.025677.
2024-01-18 20:11:54 : WARNING  test performance at epoch 3 is precision: 0.928251, recall: 0.928251, fscore: 0.928251, macro-fscore: 0.928918, right: 1035, predict: 1115, standard: 1115.
Loss is: 0.029965.
2024-01-18 20:12:10 : WARNING  Train performance at epoch 4 is precision: 0.982056, recall: 0.982056, fscore: 0.982056, macro-fscore: 0.982113, right: 2627, predict: 2675, standard: 2675.
Loss is: 0.011314.
2024-01-18 20:12:17 : WARNING  Validate performance at epoch 4 is precision: 0.955157, recall: 0.955157, fscore: 0.955157, macro-fscore: 0.955234, right: 639, predict: 669, standard: 669.
Loss is: 0.017218.
2024-01-18 20:12:25 : WARNING  test performance at epoch 4 is precision: 0.944395, recall: 0.944395, fscore: 0.944395, macro-fscore: 0.944291, right: 1053, predict: 1115, standard: 1115.
Loss is: 0.020346.
2024-01-18 20:12:33 : WARNING  Best test performance at epoch 4 is precision: 0.944395, recall: 0.944395, fscore: 0.944395, macro-fscore: 0.944291, right: 1053, predict: 1115, standard: 1115.
Loss is: 0.020346.

###################### bert_based_uncased, bert tokenized data##########
2024-01-18 20:22:57 : WARNING  Load doc_token embedding from reduced_embeddings_dict_bert.pkl
2024-01-18 20:22:57 : WARNING  Total dict size of doc_token is 26693
2024-01-18 20:22:57 : WARNING  Size of pretrained doc_token embedding is 22247
2024-01-18 20:22:57 : WARNING  Size of randomly initialize doc_token embedding is 4446
2024-01-18 20:25:02 : WARNING  dataset name: shuffled_dataset_bert_128k
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 2, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 4
loss type: SigmoidFocalCrossEntropy
optimizer: Adam
learning rate: 0.002

2024-01-18 20:25:02 : WARNING  Train performance at epoch 1 is precision: 0.959544, recall: 0.959544, fscore: 0.959544, macro-fscore: 0.957706, right: 74191, predict: 77319, standard: 77319.
Loss is: 0.018684.
2024-01-18 20:25:53 : WARNING  Validate performance at epoch 1 is precision: 0.956184, recall: 0.956184, fscore: 0.956184, macro-fscore: 0.954147, right: 18484, predict: 19331, standard: 19331.
Loss is: 0.019008.
2024-01-18 20:27:12 : WARNING  test performance at epoch 1 is precision: 0.958220, recall: 0.958220, fscore: 0.958220, macro-fscore: 0.956360, right: 30870, predict: 32216, standard: 32216.
Loss is: 0.018886.
2024-01-18 20:29:10 : WARNING  Train performance at epoch 2 is precision: 0.975323, recall: 0.975323, fscore: 0.975323, macro-fscore: 0.974200, right: 75411, predict: 77319, standard: 77319.
Loss is: 0.014864.
2024-01-18 20:30:02 : WARNING  Validate performance at epoch 2 is precision: 0.969945, recall: 0.969945, fscore: 0.969945, macro-fscore: 0.968609, right: 18750, predict: 19331, standard: 19331.
Loss is: 0.015644.
2024-01-18 20:31:24 : WARNING  test performance at epoch 2 is precision: 0.968928, recall: 0.968928, fscore: 0.968928, macro-fscore: 0.967589, right: 31215, predict: 32216, standard: 32216.
Loss is: 0.015704.
2024-01-18 20:33:23 : WARNING  Train performance at epoch 3 is precision: 0.971521, recall: 0.971521, fscore: 0.971521, macro-fscore: 0.970308, right: 75117, predict: 77319, standard: 77319.
Loss is: 0.012565.
2024-01-18 20:34:15 : WARNING  Validate performance at epoch 3 is precision: 0.964823, recall: 0.964823, fscore: 0.964823, macro-fscore: 0.963275, right: 18651, predict: 19331, standard: 19331.
Loss is: 0.013957.
2024-01-18 20:35:37 : WARNING  test performance at epoch 3 is precision: 0.964645, recall: 0.964645, fscore: 0.964645, macro-fscore: 0.963150, right: 31077, predict: 32216, standard: 32216.
Loss is: 0.013938.
2024-01-18 20:37:36 : WARNING  Train performance at epoch 4 is precision: 0.976396, recall: 0.976396, fscore: 0.976396, macro-fscore: 0.975344, right: 75494, predict: 77319, standard: 77319.
Loss is: 0.009780.
2024-01-18 20:38:28 : WARNING  Validate performance at epoch 4 is precision: 0.966272, recall: 0.966272, fscore: 0.966272, macro-fscore: 0.964752, right: 18679, predict: 19331, standard: 19331.
Loss is: 0.011941.
2024-01-18 20:39:50 : WARNING  test performance at epoch 4 is precision: 0.964055, recall: 0.964055, fscore: 0.964055, macro-fscore: 0.962486, right: 31058, predict: 32216, standard: 32216.
Loss is: 0.012125.
2024-01-18 20:41:11 : WARNING  Best test performance at epoch 2 is precision: 0.968928, recall: 0.968928, fscore: 0.968928, macro-fscore: 0.967589, right: 31215, predict: 32216, standard: 32216.
Loss is: 0.015704.




################ bert embeddings, bert tokenized##############
################# english best###############################
2024-01-19 23:25:15 : WARNING  Load doc_token embedding from r_embeddings_dict_bert_tr_mc4.pkl
2024-01-19 23:25:16 : WARNING  Total dict size of doc_token is 25321
2024-01-19 23:25:16 : WARNING  Size of pretrained doc_token embedding is 20887
2024-01-19 23:25:16 : WARNING  Size of randomly initialize doc_token embedding is 4434
2024-01-20 19:32:28 : WARNING  Load doc_token embedding from r_embeddings_dict_bert_tr_mc4.pkl
2024-01-20 19:32:29 : WARNING  Total dict size of doc_token is 26693
2024-01-20 19:32:29 : WARNING  Size of pretrained doc_token embedding is 2024
2024-01-20 19:32:29 : WARNING  Size of randomly initialize doc_token embedding is 24669
2024-01-20 19:34:04 : WARNING  Load doc_token embedding from r_bert_embeddings_en_unique_tokens.pkl
2024-01-20 19:34:05 : WARNING  Total dict size of doc_token is 26693
2024-01-20 19:34:05 : WARNING  Size of pretrained doc_token embedding is 26687
2024-01-20 19:34:05 : WARNING  Size of randomly initialize doc_token embedding is 6
2024-01-20 19:35:54 : WARNING  dataset name: shuffled_dataset_bert
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 2, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 4
loss type: SigmoidFocalCrossEntropy
optimizer: Adam
learning rate: 0.002

2024-01-20 19:35:54 : WARNING  Train performance at epoch 1 is precision: 0.964860, recall: 0.964860, fscore: 0.964860, macro-fscore: 0.963205, right: 74602, predict: 77319, standard: 77319.
Loss is: 0.016479.
2024-01-20 19:36:59 : WARNING  Validate performance at epoch 1 is precision: 0.963168, recall: 0.963168, fscore: 0.963168, macro-fscore: 0.961436, right: 18619, predict: 19331, standard: 19331.
Loss is: 0.016677.
2024-01-20 19:38:33 : WARNING  test performance at epoch 1 is precision: 0.959151, recall: 0.959151, fscore: 0.959151, macro-fscore: 0.957266, right: 30900, predict: 32216, standard: 32216.
Loss is: 0.017188.
2024-01-20 19:40:24 : WARNING  Train performance at epoch 2 is precision: 0.978686, recall: 0.978686, fscore: 0.978686, macro-fscore: 0.977711, right: 75671, predict: 77319, standard: 77319.
Loss is: 0.010539.
2024-01-20 19:41:25 : WARNING  Validate performance at epoch 2 is precision: 0.969893, recall: 0.969893, fscore: 0.969893, macro-fscore: 0.968508, right: 18749, predict: 19331, standard: 19331.
Loss is: 0.012024.
2024-01-20 19:42:57 : WARNING  test performance at epoch 2 is precision: 0.969736, recall: 0.969736, fscore: 0.969736, macro-fscore: 0.968391, right: 31241, predict: 32216, standard: 32216.
Loss is: 0.012187.
2024-01-20 19:44:57 : WARNING  Train performance at epoch 3 is precision: 0.981040, recall: 0.981040, fscore: 0.981040, macro-fscore: 0.980161, right: 75853, predict: 77319, standard: 77319.
Loss is: 0.014695.
2024-01-20 19:46:03 : WARNING  Validate performance at epoch 3 is precision: 0.971859, recall: 0.971859, fscore: 0.971859, macro-fscore: 0.970544, right: 18787, predict: 19331, standard: 19331.
Loss is: 0.016171.
2024-01-20 19:47:39 : WARNING  test performance at epoch 3 is precision: 0.969425, recall: 0.969425, fscore: 0.969425, macro-fscore: 0.968030, right: 31231, predict: 32216, standard: 32216.
Loss is: 0.016333.
2024-01-20 19:49:36 : WARNING  Train performance at epoch 4 is precision: 0.985217, recall: 0.985217, fscore: 0.985217, macro-fscore: 0.984548, right: 76176, predict: 77319, standard: 77319.
Loss is: 0.007953.
2024-01-20 19:50:39 : WARNING  Validate performance at epoch 4 is precision: 0.971962, recall: 0.971962, fscore: 0.971962, macro-fscore: 0.970674, right: 18789, predict: 19331, standard: 19331.
Loss is: 0.010843.
2024-01-20 19:52:12 : WARNING  test performance at epoch 4 is precision: 0.970605, recall: 0.970605, fscore: 0.970605, macro-fscore: 0.969290, right: 31269, predict: 32216, standard: 32216.
Loss is: 0.010826.
2024-01-20 19:53:47 : WARNING  Best test performance at epoch 4 is precision: 0.970605, recall: 0.970605, fscore: 0.970605, macro-fscore: 0.969290, right: 31269, predict: 32216, standard: 32216.
Loss is: 0.010826.


####Turkish dataset, berconv embeddings, tokenization (mc4)##
2024-01-20 23:09:37 : WARNING  Load doc_token embedding from r_turkish_bertconv_mc4.pkl
2024-01-20 23:09:37 : WARNING  Total dict size of doc_token is 25321
2024-01-20 23:09:37 : WARNING  Size of pretrained doc_token embedding is 25318
2024-01-20 23:09:37 : WARNING  Size of randomly initialize doc_token embedding is 3
2024-01-20 23:10:11 : WARNING  Load doc_token embedding from r_turkish_bertconv_mc4.pkl
2024-01-20 23:10:12 : WARNING  Total dict size of doc_token is 25321
2024-01-20 23:10:12 : WARNING  Size of pretrained doc_token embedding is 25318
2024-01-20 23:10:12 : WARNING  Size of randomly initialize doc_token embedding is 3
2024-01-20 23:10:34 : WARNING  dataset name: shuffled_dataset_bert
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 2, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 4
loss type: SigmoidFocalCrossEntropy
optimizer: Adam
learning rate: 0.002

2024-01-20 23:10:34 : WARNING  Train performance at epoch 1 is precision: 0.863178, recall: 0.863178, fscore: 0.863178, macro-fscore: 0.867055, right: 2309, predict: 2675, standard: 2675.
Loss is: 0.050800.
2024-01-20 23:10:43 : WARNING  Validate performance at epoch 1 is precision: 0.856502, recall: 0.856502, fscore: 0.856502, macro-fscore: 0.857665, right: 573, predict: 669, standard: 669.
Loss is: 0.051112.
2024-01-20 23:10:54 : WARNING  test performance at epoch 1 is precision: 0.824215, recall: 0.824215, fscore: 0.824215, macro-fscore: 0.823946, right: 919, predict: 1115, standard: 1115.
Loss is: 0.050261.
2024-01-20 23:11:14 : WARNING  Train performance at epoch 2 is precision: 0.902430, recall: 0.902430, fscore: 0.902430, macro-fscore: 0.902449, right: 2414, predict: 2675, standard: 2675.
Loss is: 0.041764.
2024-01-20 23:11:23 : WARNING  Validate performance at epoch 2 is precision: 0.898356, recall: 0.898356, fscore: 0.898356, macro-fscore: 0.898832, right: 601, predict: 669, standard: 669.
Loss is: 0.044091.
2024-01-20 23:11:34 : WARNING  test performance at epoch 2 is precision: 0.861883, recall: 0.861883, fscore: 0.861883, macro-fscore: 0.860986, right: 961, predict: 1115, standard: 1115.
Loss is: 0.045715.
2024-01-20 23:11:54 : WARNING  Train performance at epoch 3 is precision: 0.948785, recall: 0.948785, fscore: 0.948785, macro-fscore: 0.949783, right: 2538, predict: 2675, standard: 2675.
Loss is: 0.028278.
2024-01-20 23:12:03 : WARNING  Validate performance at epoch 3 is precision: 0.911809, recall: 0.911809, fscore: 0.911809, macro-fscore: 0.914594, right: 610, predict: 669, standard: 669.
Loss is: 0.033711.
2024-01-20 23:12:13 : WARNING  test performance at epoch 3 is precision: 0.898655, recall: 0.898655, fscore: 0.898655, macro-fscore: 0.902021, right: 1002, predict: 1115, standard: 1115.
Loss is: 0.034330.
2024-01-20 23:12:33 : WARNING  Train performance at epoch 4 is precision: 0.972710, recall: 0.972710, fscore: 0.972710, macro-fscore: 0.973054, right: 2602, predict: 2675, standard: 2675.
Loss is: 0.019646.
2024-01-20 23:12:42 : WARNING  Validate performance at epoch 4 is precision: 0.953662, recall: 0.953662, fscore: 0.953662, macro-fscore: 0.953756, right: 638, predict: 669, standard: 669.
Loss is: 0.024470.
2024-01-20 23:12:52 : WARNING  test performance at epoch 4 is precision: 0.936323, recall: 0.936323, fscore: 0.936323, macro-fscore: 0.936457, right: 1044, predict: 1115, standard: 1115.
Loss is: 0.026275.
2024-01-20 23:13:03 : WARNING  Best test performance at epoch 4 is precision: 0.936323, recall: 0.936323, fscore: 0.936323, macro-fscore: 0.936457, right: 1044, predict: 1115, standard: 1115.
Loss is: 0.026275.



#####################BERTurk 128k, 10epochs######################################
2024-01-21 15:11:27 : WARNING  Load doc_token embedding from r_turkish_bertconv_mc4.pkl
2024-01-21 15:11:27 : WARNING  Total dict size of doc_token is 25321
2024-01-21 15:11:27 : WARNING  Size of pretrained doc_token embedding is 25318
2024-01-21 15:11:27 : WARNING  Size of randomly initialize doc_token embedding is 3
2024-01-21 16:15:19 : WARNING  Load doc_token embedding from r_turkish_berturk_128k.pkl
2024-01-21 16:15:19 : WARNING  Total dict size of doc_token is 39584
2024-01-21 16:15:19 : WARNING  Size of pretrained doc_token embedding is 39581
2024-01-21 16:15:19 : WARNING  Size of randomly initialize doc_token embedding is 3
2024-01-21 16:15:47 : WARNING  dataset name: shuffled_dataset_bert_128k
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 2, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 10
loss type: SigmoidFocalCrossEntropy
optimizer: Adam
learning rate: 0.002

2024-01-21 16:15:47 : WARNING  Train performance at epoch 1 is precision: 0.836262, recall: 0.836262, fscore: 0.836262, macro-fscore: 0.842961, right: 2237, predict: 2675, standard: 2675.
Loss is: 0.046843.
2024-01-21 16:15:56 : WARNING  Validate performance at epoch 1 is precision: 0.822123, recall: 0.822123, fscore: 0.822123, macro-fscore: 0.829818, right: 550, predict: 669, standard: 669.
Loss is: 0.051736.
2024-01-21 16:16:07 : WARNING  test performance at epoch 1 is precision: 0.838565, recall: 0.838565, fscore: 0.838565, macro-fscore: 0.845881, right: 935, predict: 1115, standard: 1115.
Loss is: 0.044445.
2024-01-21 16:16:28 : WARNING  Train performance at epoch 2 is precision: 0.929720, recall: 0.929720, fscore: 0.929720, macro-fscore: 0.931592, right: 2487, predict: 2675, standard: 2675.
Loss is: 0.034558.
2024-01-21 16:16:37 : WARNING  Validate performance at epoch 2 is precision: 0.898356, recall: 0.898356, fscore: 0.898356, macro-fscore: 0.900200, right: 601, predict: 669, standard: 669.
Loss is: 0.042994.
2024-01-21 16:16:48 : WARNING  test performance at epoch 2 is precision: 0.918386, recall: 0.918386, fscore: 0.918386, macro-fscore: 0.921297, right: 1024, predict: 1115, standard: 1115.
Loss is: 0.037787.
2024-01-21 16:17:08 : WARNING  Train performance at epoch 3 is precision: 0.903551, recall: 0.903551, fscore: 0.903551, macro-fscore: 0.910556, right: 2417, predict: 2675, standard: 2675.
Loss is: 0.027413.
2024-01-21 16:17:17 : WARNING  Validate performance at epoch 3 is precision: 0.881913, recall: 0.881913, fscore: 0.881913, macro-fscore: 0.889381, right: 590, predict: 669, standard: 669.
Loss is: 0.033397.
2024-01-21 16:17:28 : WARNING  test performance at epoch 3 is precision: 0.882511, recall: 0.882511, fscore: 0.882511, macro-fscore: 0.893195, right: 984, predict: 1115, standard: 1115.
Loss is: 0.028602.
2024-01-21 16:17:49 : WARNING  Train performance at epoch 4 is precision: 0.970093, recall: 0.970093, fscore: 0.970093, macro-fscore: 0.970159, right: 2595, predict: 2675, standard: 2675.
Loss is: 0.015362.
2024-01-21 16:17:58 : WARNING  Validate performance at epoch 4 is precision: 0.926756, recall: 0.926756, fscore: 0.926756, macro-fscore: 0.926913, right: 620, predict: 669, standard: 669.
Loss is: 0.023973.
2024-01-21 16:18:09 : WARNING  test performance at epoch 4 is precision: 0.951570, recall: 0.951570, fscore: 0.951570, macro-fscore: 0.951609, right: 1061, predict: 1115, standard: 1115.
Loss is: 0.017754.
2024-01-21 16:18:29 : WARNING  Train performance at epoch 5 is precision: 0.979813, recall: 0.979813, fscore: 0.979813, macro-fscore: 0.979935, right: 2621, predict: 2675, standard: 2675.
Loss is: 0.017617.
2024-01-21 16:18:38 : WARNING  Validate performance at epoch 5 is precision: 0.929746, recall: 0.929746, fscore: 0.929746, macro-fscore: 0.930097, right: 622, predict: 669, standard: 669.
Loss is: 0.024806.
2024-01-21 16:18:49 : WARNING  test performance at epoch 5 is precision: 0.952466, recall: 0.952466, fscore: 0.952466, macro-fscore: 0.952717, right: 1062, predict: 1115, standard: 1115.
Loss is: 0.019648.
2024-01-21 16:19:09 : WARNING  Train performance at epoch 6 is precision: 0.989907, recall: 0.989907, fscore: 0.989907, macro-fscore: 0.989896, right: 2648, predict: 2675, standard: 2675.
Loss is: 0.007049.
2024-01-21 16:19:19 : WARNING  Validate performance at epoch 6 is precision: 0.950673, recall: 0.950673, fscore: 0.950673, macro-fscore: 0.951487, right: 636, predict: 669, standard: 669.
Loss is: 0.016060.
2024-01-21 16:19:29 : WARNING  test performance at epoch 6 is precision: 0.965919, recall: 0.965919, fscore: 0.965919, macro-fscore: 0.965971, right: 1077, predict: 1115, standard: 1115.
Loss is: 0.012808.
2024-01-21 16:19:50 : WARNING  Train performance at epoch 7 is precision: 0.994393, recall: 0.994393, fscore: 0.994393, macro-fscore: 0.994386, right: 2660, predict: 2675, standard: 2675.
Loss is: 0.004757.
2024-01-21 16:19:59 : WARNING  Validate performance at epoch 7 is precision: 0.953662, recall: 0.953662, fscore: 0.953662, macro-fscore: 0.953861, right: 638, predict: 669, standard: 669.
Loss is: 0.015840.
2024-01-21 16:20:10 : WARNING  test performance at epoch 7 is precision: 0.955157, recall: 0.955157, fscore: 0.955157, macro-fscore: 0.955331, right: 1065, predict: 1115, standard: 1115.
Loss is: 0.011891.
2024-01-21 16:20:31 : WARNING  Train performance at epoch 8 is precision: 0.996262, recall: 0.996262, fscore: 0.996262, macro-fscore: 0.996266, right: 2665, predict: 2675, standard: 2675.
Loss is: 0.002981.
2024-01-21 16:20:40 : WARNING  Validate performance at epoch 8 is precision: 0.950673, recall: 0.950673, fscore: 0.950673, macro-fscore: 0.951851, right: 636, predict: 669, standard: 669.
Loss is: 0.018175.
2024-01-21 16:20:53 : WARNING  test performance at epoch 8 is precision: 0.951570, recall: 0.951570, fscore: 0.951570, macro-fscore: 0.952453, right: 1061, predict: 1115, standard: 1115.
Loss is: 0.017342.
2024-01-21 16:21:13 : WARNING  Train performance at epoch 9 is precision: 0.998879, recall: 0.998879, fscore: 0.998879, macro-fscore: 0.998878, right: 2672, predict: 2675, standard: 2675.
Loss is: 0.002587.
2024-01-21 16:21:22 : WARNING  Validate performance at epoch 9 is precision: 0.959641, recall: 0.959641, fscore: 0.959641, macro-fscore: 0.959637, right: 642, predict: 669, standard: 669.
Loss is: 0.012879.
2024-01-21 16:21:33 : WARNING  test performance at epoch 9 is precision: 0.967713, recall: 0.967713, fscore: 0.967713, macro-fscore: 0.967766, right: 1079, predict: 1115, standard: 1115.
Loss is: 0.011006.
2024-01-21 16:21:52 : WARNING  Train performance at epoch 10 is precision: 0.999626, recall: 0.999626, fscore: 0.999626, macro-fscore: 0.999626, right: 2674, predict: 2675, standard: 2675.
Loss is: 0.000872.
2024-01-21 16:22:01 : WARNING  Validate performance at epoch 10 is precision: 0.956652, recall: 0.956652, fscore: 0.956652, macro-fscore: 0.956646, right: 640, predict: 669, standard: 669.
Loss is: 0.018681.
2024-01-21 16:22:12 : WARNING  test performance at epoch 10 is precision: 0.966816, recall: 0.966816, fscore: 0.966816, macro-fscore: 0.966927, right: 1078, predict: 1115, standard: 1115.
Loss is: 0.017356.
2024-01-21 16:22:23 : WARNING  Best test performance at epoch 9 is precision: 0.967713, recall: 0.967713, fscore: 0.967713, macro-fscore: 0.967766, right: 1079, predict: 1115, standard: 1115.
Loss is: 0.011006.
