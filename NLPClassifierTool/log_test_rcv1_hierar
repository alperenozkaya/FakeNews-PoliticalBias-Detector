2023-11-30 01:05:03 : WARNING  dataset name: WELFake_Dataset
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 1, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 4
loss type: SoftmaxCrossEntropy
optimizer: Adam
learning rate: 0.002

2023-11-30 01:05:03 : WARNING  Train performance at epoch 1 is precision: 0.941509, recall: 0.941509, fscore: 0.941509, macro-fscore: 0.941691, right: 35429, predict: 37630, standard: 37630.
Loss is: 0.148477.
2023-11-30 01:05:13 : WARNING  Validate performance at epoch 1 is precision: 0.911246, recall: 0.911246, fscore: 0.911246, macro-fscore: 0.911024, right: 8573, predict: 9408, standard: 9408.
Loss is: 0.192391.
2023-11-30 01:05:25 : WARNING  test performance at epoch 1 is precision: 0.909949, recall: 0.909949, fscore: 0.909949, macro-fscore: 0.910141, right: 14268, predict: 15680, standard: 15680.
Loss is: 0.207131.
2023-11-30 01:06:14 : WARNING  Train performance at epoch 2 is precision: 0.973425, recall: 0.973425, fscore: 0.973425, macro-fscore: 0.973532, right: 36630, predict: 37630, standard: 37630.
Loss is: 0.085961.
2023-11-30 01:06:24 : WARNING  Validate performance at epoch 2 is precision: 0.924320, recall: 0.924320, fscore: 0.924320, macro-fscore: 0.925724, right: 8696, predict: 9408, standard: 9408.
Loss is: 0.173980.
2023-11-30 01:06:36 : WARNING  test performance at epoch 2 is precision: 0.928380, recall: 0.928380, fscore: 0.928380, macro-fscore: 0.929584, right: 14557, predict: 15680, standard: 15680.
Loss is: 0.174263.
2023-11-30 01:07:27 : WARNING  Train performance at epoch 3 is precision: 0.984666, recall: 0.984666, fscore: 0.984666, macro-fscore: 0.984568, right: 37053, predict: 37630, standard: 37630.
Loss is: 0.053411.
2023-11-30 01:07:37 : WARNING  Validate performance at epoch 3 is precision: 0.918899, recall: 0.918899, fscore: 0.918899, macro-fscore: 0.917783, right: 8645, predict: 9408, standard: 9408.
Loss is: 0.200179.
2023-11-30 01:07:50 : WARNING  test performance at epoch 3 is precision: 0.921620, recall: 0.921620, fscore: 0.921620, macro-fscore: 0.920983, right: 14451, predict: 15680, standard: 15680.
Loss is: 0.203331.
2023-11-30 01:08:41 : WARNING  Train performance at epoch 4 is precision: 0.992320, recall: 0.992320, fscore: 0.992320, macro-fscore: 0.992242, right: 37341, predict: 37630, standard: 37630.
Loss is: 0.034697.
2023-11-30 01:08:51 : WARNING  Validate performance at epoch 4 is precision: 0.928571, recall: 0.928571, fscore: 0.928571, macro-fscore: 0.927614, right: 8736, predict: 9408, standard: 9408.
Loss is: 0.178364.
2023-11-30 01:09:04 : WARNING  test performance at epoch 4 is precision: 0.930421, recall: 0.930421, fscore: 0.930421, macro-fscore: 0.929628, right: 14589, predict: 15680, standard: 15680.
Loss is: 0.181075.
2023-11-30 01:09:16 : WARNING  Best test performance at epoch 4 is precision: 0.930421, recall: 0.930421, fscore: 0.930421, macro-fscore: 0.929628, right: 14589, predict: 15680, standard: 15680.
Loss is: 0.181075.
2023-12-03 11:55:11 : WARNING  dataset name: fakenewsenglish_combined
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 1, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 4
loss type: SoftmaxCrossEntropy
optimizer: Adam
learning rate: 0.002

2023-12-03 11:55:11 : WARNING  Train performance at epoch 1 is precision: 0.998423, recall: 0.998423, fscore: 0.998423, macro-fscore: 0.998414, right: 23426, predict: 23463, standard: 23463.
Loss is: 0.007973.
2023-12-03 12:02:10 : WARNING  dataset name: fakenewsenglish_combined
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 1, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 4
loss type: SoftmaxCrossEntropy
optimizer: Adam
learning rate: 0.002

2023-12-03 12:02:10 : WARNING  Train performance at epoch 1 is precision: 0.998423, recall: 0.998423, fscore: 0.998423, macro-fscore: 0.998414, right: 23426, predict: 23463, standard: 23463.
Loss is: 0.007973.
2023-12-03 12:04:52 : WARNING  dataset name: fakenewsenglish_combined
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 1, 'dropout': 0.1, 'use_star': True}
batch size: 16
num_epochs: 4
loss type: SoftmaxCrossEntropy
optimizer: Adam
learning rate: 0.002

2023-12-03 12:04:52 : WARNING  Train performance at epoch 1 is precision: 0.998380, recall: 0.998380, fscore: 0.998380, macro-fscore: 0.998371, right: 23425, predict: 23463, standard: 23463.
Loss is: 0.008096.
2023-12-03 12:08:49 : WARNING  dataset name: fakenewsenglish_combined
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 1, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 4
loss type: SoftmaxCrossEntropy
optimizer: Adam
learning rate: 0.002

2023-12-03 12:08:49 : WARNING  Train performance at epoch 1 is precision: 0.998423, recall: 0.998423, fscore: 0.998423, macro-fscore: 0.998414, right: 23426, predict: 23463, standard: 23463.
Loss is: 0.007973.
2023-12-03 12:12:31 : WARNING  dataset name: fakenewsenglish_combined
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 1, 'dropout': 0.1, 'use_star': True}
batch size: 8
num_epochs: 4
loss type: SoftmaxCrossEntropy
optimizer: Adam
learning rate: 0.002

2023-12-03 12:12:31 : WARNING  Train performance at epoch 1 is precision: 0.998039, recall: 0.998039, fscore: 0.998039, macro-fscore: 0.998027, right: 23417, predict: 23463, standard: 23463.
Loss is: 0.009544.
2023-12-03 12:20:05 : WARNING  dataset name: fakenewsenglish_combined
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 1, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 1
loss type: SoftmaxCrossEntropy
optimizer: Adam
learning rate: 0.002

2023-12-03 12:20:05 : WARNING  Train performance at epoch 1 is precision: 0.998423, recall: 0.998423, fscore: 0.998423, macro-fscore: 0.998414, right: 23426, predict: 23463, standard: 23463.
Loss is: 0.007973.
2023-12-03 12:25:53 : WARNING  dataset name: fakenewsenglish_combined
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 1, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 4
loss type: SoftmaxCrossEntropy
optimizer: Adam
learning rate: 0.002

2023-12-03 12:25:53 : WARNING  Train performance at epoch 1 is precision: 0.998423, recall: 0.998423, fscore: 0.998423, macro-fscore: 0.998414, right: 23426, predict: 23463, standard: 23463.
Loss is: 0.007973.
2023-12-03 12:26:14 : WARNING  Validate performance at epoch 1 is precision: 0.997272, recall: 0.997272, fscore: 0.997272, macro-fscore: 0.997261, right: 5850, predict: 5866, standard: 5866.
Loss is: 0.012512.
2023-12-03 12:26:36 : WARNING  test performance at epoch 1 is precision: 0.998363, recall: 0.998363, fscore: 0.998363, macro-fscore: 0.998350, right: 9760, predict: 9776, standard: 9776.
Loss is: 0.009547.
2023-12-03 12:27:41 : WARNING  Train performance at epoch 2 is precision: 0.998892, recall: 0.998892, fscore: 0.998892, macro-fscore: 0.998885, right: 23437, predict: 23463, standard: 23463.
Loss is: 0.004290.
2023-12-03 12:28:01 : WARNING  Validate performance at epoch 2 is precision: 0.997443, recall: 0.997443, fscore: 0.997443, macro-fscore: 0.997431, right: 5851, predict: 5866, standard: 5866.
Loss is: 0.009577.
2023-12-03 12:28:25 : WARNING  test performance at epoch 2 is precision: 0.998159, recall: 0.998159, fscore: 0.998159, macro-fscore: 0.998142, right: 9758, predict: 9776, standard: 9776.
Loss is: 0.009024.
2023-12-03 12:29:35 : WARNING  Train performance at epoch 3 is precision: 0.999574, recall: 0.999574, fscore: 0.999574, macro-fscore: 0.999571, right: 23453, predict: 23463, standard: 23463.
Loss is: 0.001502.
2023-12-03 12:29:55 : WARNING  Validate performance at epoch 3 is precision: 0.998295, recall: 0.998295, fscore: 0.998295, macro-fscore: 0.998289, right: 5856, predict: 5866, standard: 5866.
Loss is: 0.007823.
2023-12-03 12:30:19 : WARNING  test performance at epoch 3 is precision: 0.998568, recall: 0.998568, fscore: 0.998568, macro-fscore: 0.998556, right: 9762, predict: 9776, standard: 9776.
Loss is: 0.009268.
2023-12-03 12:31:25 : WARNING  Train performance at epoch 4 is precision: 0.999957, recall: 0.999957, fscore: 0.999957, macro-fscore: 0.999957, right: 23462, predict: 23463, standard: 23463.
Loss is: 0.000286.
2023-12-03 12:31:46 : WARNING  Validate performance at epoch 4 is precision: 0.998977, recall: 0.998977, fscore: 0.998977, macro-fscore: 0.998972, right: 5860, predict: 5866, standard: 5866.
Loss is: 0.003362.
2023-12-03 12:32:11 : WARNING  test performance at epoch 4 is precision: 0.998363, recall: 0.998363, fscore: 0.998363, macro-fscore: 0.998349, right: 9760, predict: 9776, standard: 9776.
Loss is: 0.007370.
2023-12-03 12:32:39 : WARNING  Best test performance at epoch 4 is precision: 0.998363, recall: 0.998363, fscore: 0.998363, macro-fscore: 0.998349, right: 9760, predict: 9776, standard: 9776.
Loss is: 0.007370.
2023-12-03 15:37:24 : WARNING  dataset name: fakenewsenglish_combined
model name: Transformer
model_parameters: {'d_inner': 128, 'd_k': 32, 'd_v': 32, 'n_head': 4, 'n_layers': 1, 'dropout': 0.1, 'use_star': True}
batch size: 32
num_epochs: 2
loss type: SoftmaxCrossEntropy
optimizer: Adam
learning rate: 0.002

2023-12-03 15:37:24 : WARNING  Train performance at epoch 1 is precision: 0.997564, recall: 0.997564, fscore: 0.997564, macro-fscore: 0.997564, right: 9828, predict: 9852, standard: 9852.
Loss is: 0.016229.
2023-12-03 15:37:41 : WARNING  Validate performance at epoch 1 is precision: 0.996752, recall: 0.996752, fscore: 0.996752, macro-fscore: 0.996755, right: 2455, predict: 2463, standard: 2463.
Loss is: 0.022422.
2023-12-03 15:37:58 : WARNING  test performance at epoch 1 is precision: 0.996590, recall: 0.996590, fscore: 0.996590, macro-fscore: 0.996591, right: 4091, predict: 4105, standard: 4105.
Loss is: 0.017497.
2023-12-03 15:38:40 : WARNING  Train performance at epoch 2 is precision: 0.999086, recall: 0.999086, fscore: 0.999086, macro-fscore: 0.999086, right: 9843, predict: 9852, standard: 9852.
Loss is: 0.004607.
2023-12-03 15:38:57 : WARNING  Validate performance at epoch 2 is precision: 0.997970, recall: 0.997970, fscore: 0.997970, macro-fscore: 0.997970, right: 2458, predict: 2463, standard: 2463.
Loss is: 0.009989.
2023-12-03 15:39:14 : WARNING  test performance at epoch 2 is precision: 0.996833, recall: 0.996833, fscore: 0.996833, macro-fscore: 0.996836, right: 4092, predict: 4105, standard: 4105.
Loss is: 0.010610.
2023-12-03 15:39:32 : WARNING  Best test performance at epoch 2 is precision: 0.996833, recall: 0.996833, fscore: 0.996833, macro-fscore: 0.996836, right: 4092, predict: 4105, standard: 4105.
Loss is: 0.010610.
